{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import pickle\n",
    "import sklearn\n",
    "import gc\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "#from twilio.rest import Client\n",
    "from twilio_functions import send_sms\n",
    "#import theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\King Haus Ho 2.0\\\\Documents\\\\data_science\\\\train.csv'\n",
    "p = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    p\n",
    "    raw_df = pd.read_csv(\n",
    "             filename, \n",
    "             dtype = {'PuaMode':object},\n",
    "             skiprows=lambda i: i>0 and random.random() > p\n",
    "    )\n",
    "except:\n",
    "    raw_df = pd.read_csv(\n",
    "             filename, \n",
    "             dtype = {'PuaMode':object}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = raw_df['HasDetections'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x_df = (raw_df.loc[:,raw_df.columns[~raw_df.columns.isin(['MachineIdentifier',\n",
    "                                                          'HasDetections',\n",
    "                                                          'RtpStateBitfield',\n",
    "                                                          'IsSxsPassiveMode',\n",
    "                                                          'AVProductsInstalled',\n",
    "                                                          'AVProductsEnabled',\n",
    "                                                          'IeVerIdentifier',\n",
    "                                                          'Census_OEMNameIdentifier',\n",
    "                                                          'Census_OEMModelIdentifier',\n",
    "                                                          'Census_ProcessorManufacturerIdentifier',\n",
    "                                                          'Census_ProcessorModelIdentifier ',\n",
    "                                                          'Census_InternalBatteryType',\n",
    "                                                          'Census_InternalBatteryNumberOfCharges',\n",
    "                                                          'Census_OSInstallLanguageIdentifier',\n",
    "                                                          'Census_OSUILocaleIdentifier',\n",
    "                                                          'Census_IsFlightingInternal',\n",
    "                                                          'Census_ThresholdOptIn',\n",
    "                                                          'Census_FirmwareManufacturerIdentifier',\n",
    "                                                          'Census_FirmwareVersionIdentifier',\n",
    "                                                          'Census_IsWIMBootEnabled',\n",
    "                                                          'Wdft_RegionIdentifier',\n",
    "                                                          'Census_ProcessorClass',\n",
    "                                                          'Census_ProcessorModelIdentifier'])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = (['Census_PrimaryDiskTotalCapacity',\n",
    "             'Census_SystemVolumeTotalCapacity',\n",
    "             'Census_TotalPhysicalRAM',\n",
    "             'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "             'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "             'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "             'Census_ProcessorCoreCount'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate categorical variables\n",
    "category_df = raw_x_df.loc[:,raw_x_df.columns[~raw_x_df.columns.isin(num_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = category_df.astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate numerical variables\n",
    "num_df = raw_x_df.loc[:,num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = category_df\n",
    "cat_df['AvSigVersion'] = cat_df['AvSigVersion'].str[0:5]\n",
    "exclude_cols = ['AVProductStatesIdentifier',\n",
    "                'CityIdentifier',\n",
    "                'DefaultBrowsersIdentifier',\n",
    "                'GeoNameIdentifier',\n",
    "                'LocaleEnglishNameIdentifier',\n",
    "                'OsPlatformSubRelease',\n",
    "                'Census_OSBuildRevision',\n",
    "                'OsBuildLab']\n",
    "cat_df = cat_df.loc[:,cat_df.columns[~cat_df.columns.isin(exclude_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark missing categorical vars\n",
    "for col in cat_df:\n",
    "    #max_freq = category_df[col].value_counts().index[0]\n",
    "    cat_df[col][pd.isna(cat_df[col])] = 'MISSING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale num vars prior to imputation\n",
    "scalar = StandardScaler()\n",
    "scaled_num_df = pd.DataFrame(scalar.fit_transform(num_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform inductive, single imputation with numerical df\n",
    "#NOTE: Will not attempt multiple imputation\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_num_df = pd.DataFrame(imp_freq.fit_transform(scaled_num_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_num_df.index = scaled_num_df.index\n",
    "imp_num_df.columns = scaled_num_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categories into nominal integers\n",
    "le_dict = {}\n",
    "label_df = pd.DataFrame()\n",
    "for col in cat_df:\n",
    "    le = LabelEncoder()\n",
    "    label_df[col] = le.fit_transform(cat_df[col].astype(str))\n",
    "    le_dict[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_df, raw_x_df, category_df, cat_df, num_df, scaled_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#create df of binary cols representing instance of each category across multipile columns\n",
    "enc = OneHotEncoder()\n",
    "onehot_df = pd.DataFrame(enc.fit_transform(label_df).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df of x,y vars from imputed df and encoded df\n",
    "x_df = pd.concat([imp_num_df, onehot_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del onehot_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split x and y data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df,\n",
    "                                  y_df,\n",
    "                                  test_size=0.2,\n",
    "                                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring metric to optimize\n",
    "#score = 'roc_auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='Adagrad',\n",
    "                 init_mode='he_normal',\n",
    "                 activation = 'softsign',\n",
    "                 dropout_rate=0.9,\n",
    "                 weight_constraint=5,\n",
    "                 neurons = 1500):\n",
    "    # create model\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(neurons,\n",
    "                  kernel_initializer=init_mode,\n",
    "                  input_dim=len(X_train.columns),\n",
    "                  activation=activation,\n",
    "                  kernel_constraint=maxnorm(weight_constraint)))\n",
    "    clf.add(Dropout(dropout_rate))\n",
    "    clf.add(Dense(1,\n",
    "                  activation='sigmoid'))\n",
    "    # Compile model\n",
    "    clf.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(build_fn=create_model,\n",
    "                      epochs=100,\n",
    "                      batch_size=150,\n",
    "                      verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "neurons = [1500]\n",
    "param_grid = dict(neurons=neurons)\n",
    "cv = 5\n",
    "grid = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM97d198888ded4e02a85bdd063943ee45\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    grid_result = grid.fit(X_train.values,\n",
    "                       y_train.values)\n",
    "    # summarize results\n",
    "    body = \"Finished training.\"\n",
    "    sms = send_sms(body)\n",
    "    print(sms)\n",
    "    \n",
    "except:\n",
    "    body = \"Training failed\"\n",
    "    sms = send_sms(body)\n",
    "    print(sms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grid', 'wb') as f:\n",
    "        pickle.dump(grid, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6738096625912189\n"
     ]
    }
   ],
   "source": [
    "# new instances where we do not know the answer\n",
    "clf_probs = grid.predict_proba(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, clf_probs[:,1]))\n",
    "#print('Accuracy: ', clf3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "321px",
    "left": "711px",
    "right": "20px",
    "top": "138px",
    "width": "530px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
